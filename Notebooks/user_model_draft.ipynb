{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, RepeatedKFold, StratifiedKFold\n",
    "import time \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sb"
   ],
   "id": "7a020d8717b4e494",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_user_animelist(username: str, client_id: str):\n",
    "    # Loads list of anime from MAL for a given user\n",
    "    url = f'https://api.myanimelist.net/v2/users/{username}/animelist?limit=500'\n",
    "    headers = {\n",
    "        'X-MAL-CLIENT-ID': client_id\n",
    "    }\n",
    "    params = {\n",
    "        'fields': 'id, title, list_status{score,status}, start_season{year}, mean, genres, popularity, media_type, rating, num_episodes, studios, num_list_users,favorites'\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "    next_page = url\n",
    "\n",
    "    while next_page:\n",
    "        response = requests.get(next_page, headers=headers, params=params if next_page == url else None)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Error with API request: {response.status_code} - {response.text}\")\n",
    "\n",
    "        data = response.json()\n",
    "        all_data.extend(data['data'])\n",
    "        next_page = data.get(\"paging\", {}).get(\"next\")\n",
    "\n",
    "        print(f\"Loaded {len(all_data)} anime...\")\n",
    "\n",
    "    return all_data"
   ],
   "id": "d7052a10b430a951",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def to_dataframe(all_data):\n",
    "    rows = []\n",
    "    for item in all_data:\n",
    "        anime = item['node']\n",
    "        score = item.get('list_status', {}).get('score')\n",
    "        status = item.get('list_status', {}).get('status')\n",
    "        # num_episodes_watched = item.get('list_status', {}).get('num_episodes_watched')\n",
    "        year = item.get('node', {}).get('start_season', {}).get('year')\n",
    "        rows.append({\n",
    "            \"id\": anime['id'],\n",
    "            \"title\": anime['title'],\n",
    "            \"mean\": anime.get('mean'),\n",
    "            \"genres\": [g['name'] for g in anime.get('genres', [])],\n",
    "            \"studios\": [s['name'] for s in anime.get('studios', [])],\n",
    "            \"rating\": anime.get('rating'),\n",
    "            \"year\": year,\n",
    "            \"type\": anime.get('media_type'),\n",
    "            \"popularity\": anime.get('popularity'),\n",
    "            \"score\": score,\n",
    "            \"status\": status,\n",
    "            \"members\": anime['num_list_users'],\n",
    "            \"num_episodes\": anime['num_episodes'],\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df['studios'] = df['studios'].str.join(\", \")\n",
    "    df['genres'] = df['genres'].str.join(\", \")\n",
    "\n",
    "    return df"
   ],
   "id": "a2e71aabff7eb53a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_genre_affinity_simple(df_train):\n",
    "    genre_cols = [col for col in df_train.columns if col.startswith('Genre_')]\n",
    "    genre_affinity = {}\n",
    "    \n",
    "    overall_mean = df_train['score'].mean()\n",
    "    \n",
    "    for genre_col in genre_cols:\n",
    "        genre_name = genre_col.replace('Genre_', '')\n",
    "        mask = df_train[genre_col] == 1\n",
    "        \n",
    "        if mask.sum() >= 5:\n",
    "            genre_affinity[genre_name] = df_train[mask]['score'].mean()\n",
    "        else:\n",
    "            genre_affinity[genre_name] = overall_mean\n",
    "    \n",
    "    return genre_affinity"
   ],
   "id": "6e3e9e46badc3341",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_studio_mean(df_train):\n",
    "    studios_columns = [col for col in df_train.columns if col.startswith('Studios_')]\n",
    "    studio_mean = {}\n",
    "    overall_mean = df_train['score'].mean()\n",
    "    for studio_column in studios_columns:\n",
    "        studio_name = studio_column.replace('Studios_', '')\n",
    "        mask = df_train[studio_column] == 1\n",
    "        \n",
    "        if mask.sum() >= 3:\n",
    "            studio_scores = df_train[mask]['score']\n",
    "            mean_score = studio_scores.mean()\n",
    "            studio_mean[studio_name] = mean_score\n",
    "        else:\n",
    "            studio_mean[studio_name] = overall_mean\n",
    "            \n",
    "    return studio_mean"
   ],
   "id": "54d95a0cedfdc24",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def classify_3_classes(score):\n",
    "    if score <= 5:\n",
    "        return 0\n",
    "    elif score <= 7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ],
   "id": "1e30eeb95e58c888",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "USER_NAME = config.get('USER','USER_NAME').strip()\n",
    "CLIENT_ID = config.get('USER','CLIENT_ID').strip()"
   ],
   "id": "2b3d7ad773319581",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = get_user_animelist(USER_NAME, CLIENT_ID)",
   "id": "e493f342e7d95fb8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = to_dataframe(data)",
   "id": "4e1e4c2201d6987f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['score_class'] = df['score'].apply(classify_3_classes)",
   "id": "b67adf4b685b09dd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['studios'] = df['studios'].replace('', 'Unknown')\n",
    "df['genres'] = df['genres'].replace('', 'Unknown')\n",
    "\n",
    "df = df.dropna(subset=['score'])"
   ],
   "id": "656c118c51421dfd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(df[\"score\"].value_counts().head(11))",
   "id": "f269c82f26651821",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.drop(columns=['title', 'id'], inplace=True)",
   "id": "cb5cda6ffb3bb23c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df[df['score'] > 0].copy()\n",
    "    \n",
    "df['mean'] = df['mean'].fillna(df.groupby('type')['mean'].transform('median'))\n",
    "    \n",
    "categorical_cols = ['type', 'rating', 'status']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('Unknown')"
   ],
   "id": "6fc3a7bc389d858e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['year'] = df['year'].fillna(df['year'].mode()[0])\n",
    "df['num_episodes'] = df['num_episodes'].fillna(df['num_episodes'].mode()[0])"
   ],
   "id": "bb92a571b7833b0f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['popularity'] = df['popularity'].fillna(df['popularity'].median())",
   "id": "822f30ae0069e0dd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['anime_age'] = 2025 - df['year']\n",
    "df['anime_age'] = df['anime_age'].astype(int)\n",
    "df.drop(columns=['year'], inplace=True)"
   ],
   "id": "48ad632da83ec0f2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['log_members'] = np.log1p(df['members'])\n",
    "df.drop(columns=['members'], inplace=True)"
   ],
   "id": "96c72ca71b313fb9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get dummy variables for each unique genre\n",
    "genre_dummies = (\n",
    "    df['genres']\n",
    "    .str.split(', ', expand=True) \n",
    "    .stack()       \n",
    "    .str.get_dummies()         \n",
    "    .groupby(level=0)         \n",
    "    .sum()                    \n",
    "    .add_prefix('Genre_')  \n",
    ")"
   ],
   "id": "9d52098ed6f3cf6f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.concat([df, genre_dummies], axis=1)",
   "id": "a87bf71c326a8336",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genre_columns = [col for col in df.columns if col.startswith('Genre_')]\n",
    "\n",
    "genre_counts = df[genre_columns].sum().sort_values(ascending=False)\n",
    "print(genre_counts)"
   ],
   "id": "1bb6561a86cbb474",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genre_columns = [col for col in df.columns if col.startswith('Genre_')]\n",
    "\n",
    "genre_counts = df[genre_columns].sum().sort_values(ascending=False)\n",
    "total_anime = len(df)\n",
    "\n",
    "min_count = max(5, int(total_anime * 0.01))\n",
    "frequent_genres= genre_counts[genre_counts >= min_count].index.tolist()\n",
    "\n",
    "print(f\"studio_counts: {len(genre_counts)}\")\n",
    "print(f\"Studios with >= {min_count} anime: {len(frequent_genres)}\")\n",
    "\n",
    "rare_genre_columns = [col for col in genre_columns if col not in frequent_genres]\n",
    "df['Genre_Other'] = df[rare_genre_columns].max(axis=1) \n",
    "\n",
    "df.drop(columns=rare_genre_columns, inplace=True)"
   ],
   "id": "3e519fde77276f18",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.drop(columns=['genres'], inplace=True)",
   "id": "daddb430b065ba5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "type_dummies = pd.get_dummies(df['type'], prefix='Type')\n",
    "df = pd.concat([df, type_dummies], axis=1)\n",
    "df.drop(columns=['type'], inplace=True)"
   ],
   "id": "bd71a70d384c6a63",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "studio_dummies = (\n",
    "    df['studios']\n",
    "    .str.split(', ', expand=True) \n",
    "    .stack()       \n",
    "    .str.get_dummies()         \n",
    "    .groupby(level=0)         \n",
    "    .sum()                    \n",
    "    .add_prefix('Studios_')  \n",
    ")\n",
    "df = pd.concat([df, studio_dummies], axis=1)"
   ],
   "id": "ac0c9e49f86d4346",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "studio_columns = [col for col in df.columns if col.startswith('Studios_')]\n",
    "\n",
    "studio_counts = df[studio_columns].sum().sort_values(ascending=False)\n",
    "print(studio_counts)"
   ],
   "id": "ff2e29326d8858a7",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "studio_columns = [col for col in df.columns if col.startswith('Studios_')]\n",
    "\n",
    "studio_counts = df[studio_columns].sum().sort_values(ascending=False)\n",
    "total_anime = len(df)\n",
    "\n",
    "min_count = max(10, int(total_anime * 0.01))\n",
    "frequent_studios = studio_counts[studio_counts >= min_count].index.tolist()\n",
    "\n",
    "print(f\"studio_counts: {len(studio_counts)}\")\n",
    "print(f\"Studios with >= {min_count} anime: {len(frequent_studios)}\")\n",
    "\n",
    "rare_studio_columns = [col for col in studio_columns if col not in frequent_studios]\n",
    "df['Studio_Other'] = df[rare_studio_columns].max(axis=1) \n",
    "\n",
    "df.drop(columns=rare_studio_columns, inplace=True)"
   ],
   "id": "de5c950b1cb5b30b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.drop(columns=['studios'], inplace=True)",
   "id": "c014655891dbcd8a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rating_dummies = pd.get_dummies(df['rating'], prefix='Rating')\n",
    "df = pd.concat([df, rating_dummies], axis=1)\n",
    "df.drop(columns=['rating'], inplace=True)"
   ],
   "id": "126fb5dbd378ec10",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "status_dummies = pd.get_dummies(df['status'], prefix='Status')\n",
    "df = pd.concat([df, status_dummies], axis=1)\n",
    "df.drop(columns=['status'], inplace=True)"
   ],
   "id": "bbca1d6b46517b34",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.drop(columns=['Status_completed'], inplace=True)\n",
    "df.drop(columns=['Type_tv'], inplace=True)\n",
    "df.drop(columns=['Rating_pg_13'], inplace=True)"
   ],
   "id": "3dbf969c4c19971a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bool_cols = df.select_dtypes('bool').columns\n",
    "\n",
    "df[bool_cols] = df[bool_cols].astype(int)"
   ],
   "id": "912256dec29366ff",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# df.drop(columns=['Genre_Unknown'], inplace=True)",
   "id": "ddcccea889c0e4c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_with_score = df.corr()['score']\n",
    "high_corr_cols = corr_with_score[np.abs(corr_with_score) > 0.65].index\n",
    "high_corr_cols = high_corr_cols.drop(['score','score_class'])\n",
    "print(high_corr_cols)"
   ],
   "id": "e334eebf17fd9a70",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.drop(columns=high_corr_cols, inplace=True)",
   "id": "e4735cd8df6e9a53",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['num_episodes'] = np.log1p(df['num_episodes'])",
   "id": "1968790fd8a3d54f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.drop(columns=['popularity'], inplace=True)\n",
    "# df.drop(columns=['log_members'], inplace=True)"
   ],
   "id": "88b876a20413b99f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(columns=['score', 'score_class'])\n",
    "y = df['score_class']"
   ],
   "id": "27bd2952506f29c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)",
   "id": "9dc3c5852237c268",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genre_affinity = calculate_genre_affinity_simple(X_train.join(df['score']))\n",
    "\n",
    "affinity_features_train = pd.DataFrame({\n",
    "    f\"affinity_{genre}\": X_train[f\"Genre_{genre}\"] * affinity\n",
    "    for genre, affinity in genre_affinity.items()\n",
    "}, index=X_train.index)\n",
    "\n",
    "affinity_features_test = pd.DataFrame({\n",
    "    f\"affinity_{genre}\": X_test[f\"Genre_{genre}\"] * affinity\n",
    "    for genre, affinity in genre_affinity.items()\n",
    "}, index=X_test.index)\n",
    "\n",
    "X_train = pd.concat([X_train, affinity_features_train], axis=1)\n",
    "X_test = pd.concat([X_test, affinity_features_test], axis=1)"
   ],
   "id": "389db8069494dd07",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = X_train.drop(columns=[col for col in X_train.columns if col.startswith(\"Genre_\")])\n",
    "X_test = X_test.drop(columns=[col for col in X_test.columns if col.startswith(\"Genre_\")])"
   ],
   "id": "53c1fc6750ab121b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# studios_affinity = calculate_studio_mean(X_train.join(df['score']))\n",
    "# \n",
    "# affinity_features_train = pd.DataFrame({\n",
    "#     f\"affinity_{studio}\": X_train[f\"Studios_{studio}\"] * affinity\n",
    "#     for studio, affinity in studios_affinity.items()\n",
    "# }, index=X_train.index)\n",
    "# \n",
    "# affinity_features_test = pd.DataFrame({\n",
    "#     f\"affinity_{studio}\": X_test[f\"Studios_{studio}\"] * affinity\n",
    "#     for studio, affinity in studios_affinity.items()\n",
    "# }, index=X_test.index)\n",
    "# \n",
    "# X_train = pd.concat([X_train, affinity_features_train], axis=1)\n",
    "# X_test = pd.concat([X_test, affinity_features_test], axis=1)"
   ],
   "id": "18dbf99544f28739",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# X_train = X_train.drop(columns=[col for col in X_train.columns if col.startswith(\"Studios_\")])\n",
    "# X_test = X_test.drop(columns=[col for col in X_test.columns if col.startswith(\"Studios_\")])"
   ],
   "id": "da1b15d5f6ce31a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.sample(10)",
   "id": "b158752ee61dce4f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ],
   "id": "8f70a6ce40a10b09",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ],
   "id": "b70d9b860f738f78",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(class_weight_dict)",
   "id": "255b11412873fe9f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = CatBoostClassifier(early_stopping_rounds=50,random_state=42, verbose=0)",
   "id": "5f0894163ec5c515",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'iterations': [200, 300, 400],\n",
    "    'depth': [3, 4, 6],\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'l2_leaf_reg': [3, 5, 7],\n",
    "    'random_strength': [1.0, 1.5]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=24)\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    scoring='f1_macro',\n",
    "    cv=cv,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True  \n",
    ")"
   ],
   "id": "d2a75515c8b19690",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid.fit(\n",
    "    X_train, y_train\n",
    ")"
   ],
   "id": "59968bc63a9d0cb9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results = results.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "print(results[[\n",
    "    \"param_depth\",\n",
    "    \"param_iterations\",\n",
    "    \"param_learning_rate\",\n",
    "    \"param_l2_leaf_reg\",\n",
    "    \"param_random_strength\",\n",
    "    \"mean_test_score\",\n",
    "    \"std_test_score\"\n",
    "]].head(10))"
   ],
   "id": "89607d6bcda4b9e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = CatBoostClassifier(\n",
    "    depth=4,\n",
    "    l2_leaf_reg=3,\n",
    "    eval_metric='MultiClass', \n",
    "    class_weights=class_weight_dict, \n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")"
   ],
   "id": "1af7e67141c80bd8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=(X_val, y_val),\n",
    "    use_best_model=True\n",
    ")"
   ],
   "id": "825da9d01d28016b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_pred = model.predict(X_test)",
   "id": "3543ad1674b31069",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Dont Watch', 'Okay', 'Good'],\n",
    "            yticklabels=['Dont Watch', 'Okay', 'Good'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=['Dont Watch', 'Okay', 'Good']))"
   ],
   "id": "4514298561090d5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save_model(\"../models/catboost_model.cbm\")",
   "id": "5c59357b87141886",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8dfce20bdc505ef5",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
