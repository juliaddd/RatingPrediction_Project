{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:18.889425Z",
     "start_time": "2025-10-05T12:02:18.452377Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import configparser\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LOADING DATA FROM API\n",
   "id": "b58d658f083d74d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:18.905459Z",
     "start_time": "2025-10-05T12:02:18.889425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_user_animelist(username: str, client_id: str):\n",
    "    # Loads list of anime from MAL for a given user\n",
    "    url = f'https://api.myanimelist.net/v2/users/{username}/animelist?limit=500'\n",
    "    headers = {\n",
    "        'X-MAL-CLIENT-ID': client_id\n",
    "    }\n",
    "    params = {\n",
    "        'fields': 'id, title, list_status{score,status}, start_season{year}, mean, genres, popularity, media_type, rating, num_episodes, studios, num_list_users,favorites'\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "    next_page = url\n",
    "\n",
    "    while next_page:\n",
    "        response = requests.get(next_page, headers=headers, params=params if next_page == url else None)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Error with API request: {response.status_code} - {response.text}\")\n",
    "\n",
    "        data = response.json()\n",
    "        all_data.extend(data['data'])\n",
    "        next_page = data.get(\"paging\", {}).get(\"next\")\n",
    "\n",
    "        print(f\"Loaded {len(all_data)} anime...\")\n",
    "\n",
    "    return all_data"
   ],
   "id": "31a6366b6bd8450f",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:18.921195Z",
     "start_time": "2025-10-05T12:02:18.908855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_dataframe(all_data):\n",
    "    rows = []\n",
    "    for item in all_data:\n",
    "        anime = item['node']\n",
    "        score = item.get('list_status', {}).get('score')\n",
    "        status = item.get('list_status', {}).get('status')\n",
    "        # num_episodes_watched = item.get('list_status', {}).get('num_episodes_watched')\n",
    "        year = item.get('node', {}).get('start_season', {}).get('year')\n",
    "        rows.append({\n",
    "            \"id\": anime['id'],\n",
    "            \"title\": anime['title'],\n",
    "            \"mean\": anime.get('mean'),\n",
    "            \"genres\": [g['name'] for g in anime.get('genres', [])],\n",
    "            \"studios\": [s['name'] for s in anime.get('studios', [])],\n",
    "            \"rating\": anime.get('rating'),\n",
    "            \"year\": year,\n",
    "            \"type\": anime.get('media_type'),\n",
    "            \"popularity\": anime.get('popularity'),\n",
    "            \"score\": score,\n",
    "            \"status\": status,\n",
    "            \"members\": anime['num_list_users'],\n",
    "            \"num_episodes\": anime['num_episodes'],\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df['studios'] = df['studios'].str.join(\", \")\n",
    "    df['genres'] = df['genres'].str.join(\", \")\n",
    "\n",
    "    return df"
   ],
   "id": "f8a37d1583d9841d",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:18.952763Z",
     "start_time": "2025-10-05T12:02:18.921195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "USER_NAME = config.get('USER','USER_NAME').strip()\n",
    "CLIENT_ID = config.get('USER','CLIENT_ID').strip()"
   ],
   "id": "d85a420c2c945fb9",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:27.182165Z",
     "start_time": "2025-10-05T12:02:18.952763Z"
    }
   },
   "cell_type": "code",
   "source": "data = get_user_animelist(USER_NAME, CLIENT_ID)",
   "id": "e7fe2c11394af7dc",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## WORKING WITH DATAFRAME",
   "id": "21152c8f6be71b44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:29.773484Z",
     "start_time": "2025-10-05T12:02:29.673373Z"
    }
   },
   "cell_type": "code",
   "source": "df = to_dataframe(data)",
   "id": "aafebefc5d88b650",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### FUNCTIONS FOR DATA PREPROCESSING",
   "id": "8e71735d15eb68bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:32.259064Z",
     "start_time": "2025-10-05T12:02:32.243289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df = df[df['score'] > 0]\n",
    "    \n",
    "    categorical_cols = ['studios', 'genres', 'rating', 'status', 'type']\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "        df[col] = df[col].replace('', 'Unknown')\n",
    "    \n",
    "    numerical_cols = ['year', 'mean', 'popularity', 'members', 'num_episodes']\n",
    "    for col in numerical_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df"
   ],
   "id": "f2876978a98c5bc3",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:34.869886Z",
     "start_time": "2025-10-05T12:02:34.853978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encoding(df):\n",
    "    \n",
    "    status_dummies = pd.get_dummies(df['status'], prefix='Status')\n",
    "    df = pd.concat([df, status_dummies], axis=1)\n",
    "    \n",
    "    type_dummies = pd.get_dummies(df['type'], prefix='Type')\n",
    "    df = pd.concat([df, type_dummies], axis=1)\n",
    "    \n",
    "    rating_dummies = pd.get_dummies(df['rating'], prefix='Rating')\n",
    "    df = pd.concat([df, rating_dummies], axis=1)\n",
    "    \n",
    "    genre_dummies = (\n",
    "    df['genres']\n",
    "    .str.split(', ', expand=True) \n",
    "    .stack()       \n",
    "    .str.get_dummies()         \n",
    "    .groupby(level=0)         \n",
    "    .sum()                    \n",
    "    .add_prefix('Genre_')  \n",
    "    )\n",
    "    df = pd.concat([df, genre_dummies], axis=1)\n",
    "\n",
    "    \n",
    "    studio_dummies = (\n",
    "    df['studios']\n",
    "    .str.split(', ', expand=True) \n",
    "    .stack()       \n",
    "    .str.get_dummies()         \n",
    "    .groupby(level=0)         \n",
    "    .sum()                    \n",
    "    .add_prefix('Studios_')  \n",
    "    )\n",
    "    df = pd.concat([df, studio_dummies], axis=1)\n",
    "\n",
    "    df.drop(columns=['genres'], inplace=True)\n",
    "    df.drop(columns=['studios'], inplace=True)\n",
    "    df.drop(columns=['type', 'Type_tv'], inplace=True)\n",
    "    df.drop(columns=['rating', 'Rating_pg_13'], inplace=True)\n",
    "    df.drop(columns=['status', 'Status_completed'], inplace=True)\n",
    "    \n",
    "    return df"
   ],
   "id": "dc3f56401896add1",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:37.495425Z",
     "start_time": "2025-10-05T12:02:37.475944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_for_rules(df):\n",
    "    \"\"\"\n",
    "    Preprocessing for rule-based system\n",
    "    Keep all original features\n",
    "    \"\"\"\n",
    "    df = preprocess(df)  # Fill nulls\n",
    "    df = one_hot_encoding(df)  # One-hot encode\n",
    "    \n",
    "    return df"
   ],
   "id": "4f907b244828a8b9",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:38.761001Z",
     "start_time": "2025-10-05T12:02:38.757982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_3_classes(score, q33,q66):\n",
    "\n",
    "    if score <= q33:\n",
    "        return 0\n",
    "    elif score <= q66:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ],
   "id": "81a6b963c781e110",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:51.884696Z",
     "start_time": "2025-10-05T12:02:51.859907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_for_ml(df, q33=None, q66=None, drop_mean=True):\n",
    "\n",
    "    df = preprocess(df)\n",
    "    df = one_hot_encoding(df)\n",
    "\n",
    "    if q33 is not None and q66 is not None:\n",
    "        df['score_class'] = df['score'].apply(lambda s: classify_3_classes(s, q33, q66))\n",
    "    else:\n",
    "        df['score_class'] = df['score'].apply(classify_3_classes)\n",
    "        \n",
    "    genre_cols = [col for col in df.columns if col.startswith('Genre_')]\n",
    "    df['num_genres'] = df[genre_cols].sum(axis=1) \n",
    "    \n",
    "    if drop_mean and 'mean' in df.columns:\n",
    "        df = df.drop(columns=['mean'])\n",
    "    \n",
    "    # Log transformations\n",
    "    if 'popularity' in df.columns:\n",
    "        df['popularity'] = np.log1p(df['popularity'])\n",
    "    if 'members' in df.columns:\n",
    "        df.drop(columns=['members'], inplace=True )\n",
    "    \n",
    "    if 'num_episodes' in df.columns:\n",
    "        df['num_episodes'] = np.log1p(df['num_episodes'])\n",
    "    \n",
    "    # Create anime_age if year exists\n",
    "    if 'year' in df.columns:\n",
    "        df['anime_age'] = 2025 - df['year']\n",
    "        df = df.drop(columns=['year'])\n",
    "        \n",
    "    if 'anime_age' in df.columns:\n",
    "        df['age_category'] = pd.cut(\n",
    "            df['anime_age'],\n",
    "            bins=[-1, 2, 5, 10, 20, np.inf],\n",
    "            labels=['new', 'recent', 'modern', 'old', 'classic']\n",
    "        )\n",
    "        df = pd.get_dummies(df, columns=['age_category'], drop_first=True)\n",
    "        df = df.drop(columns=['anime_age'])\n",
    "        \n",
    "    if 'num_episodes' in df.columns:\n",
    "        df['episode_cat'] = pd.cut(\n",
    "            df['num_episodes'],\n",
    "            bins=[0,1,10,18,26,57,np.inf],\n",
    "            labels=['single', 'short', 'one_season','two_season', 'long', 'very_long'] # 1, 2-10, 11-18, 18-26,25-57,58-\n",
    "        )\n",
    "        df = pd.get_dummies(df, columns=['episode_cat'], drop_first=True)\n",
    "        df = df.drop(columns=['num_episodes'])\n",
    "        \n",
    "    return df"
   ],
   "id": "de34193646025c30",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:02:53.989147Z",
     "start_time": "2025-10-05T12:02:53.973134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_genre_affinity(df_train):\n",
    "    genre_cols = [col for col in df_train.columns if col.startswith('Genre_')]\n",
    "    genre_affinity = {}\n",
    "    \n",
    "    overall_mean = df_train['score'].mean()\n",
    "    \n",
    "    for genre_col in genre_cols:\n",
    "        genre_name = genre_col.replace('Genre_', '')\n",
    "        mask = df_train[genre_col] == 1\n",
    "        \n",
    "        if mask.sum() >= 5:\n",
    "            genre_affinity[genre_name] = df_train[mask]['score'].mean()\n",
    "        else:\n",
    "            genre_affinity[genre_name] = overall_mean\n",
    "    \n",
    "    return genre_affinity"
   ],
   "id": "4cfcadd362c6e8ae",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:08:20.761859Z",
     "start_time": "2025-10-05T12:08:20.746108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def use_affinity(X_train, X_test, y_train):\n",
    "    genre_affinity = calculate_genre_affinity(X_train.join(y_train))\n",
    "\n",
    "    affinity_features_train = pd.DataFrame({\n",
    "    f\"affinity_{genre}\": X_train[f\"Genre_{genre}\"] * affinity\n",
    "    for genre, affinity in genre_affinity.items()\n",
    "    }, index=X_train.index)\n",
    "\n",
    "    affinity_features_test = pd.DataFrame({\n",
    "    f\"affinity_{genre}\": X_test[f\"Genre_{genre}\"] * affinity\n",
    "    for genre, affinity in genre_affinity.items()\n",
    "    }, index=X_test.index)\n",
    "\n",
    "    X_train = pd.concat([X_train, affinity_features_train], axis=1)\n",
    "    X_test = pd.concat([X_test, affinity_features_test], axis=1)\n",
    "    \n",
    "    X_train = X_train.drop(columns=[col for col in X_train.columns if col.startswith(\"Genre_\")])\n",
    "    X_test = X_test.drop(columns=[col for col in X_test.columns if col.startswith(\"Genre_\")])\n",
    "    \n",
    "    return X_train,X_test"
   ],
   "id": "b2a7d8fb0f6c7bf7",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:08:21.046732Z",
     "start_time": "2025-10-05T12:08:21.014741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_rare_features(df_train, df_test):\n",
    "    df_train = df_train.copy()\n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    total_anime = len(df_train)\n",
    "    \n",
    "    # === GENRES ===\n",
    "    genre_columns = [col for col in df_train.columns if col.startswith('Genre_')]\n",
    "    genre_counts = df_train[genre_columns].sum().sort_values(ascending=False)\n",
    "    \n",
    "    min_count = max(5, int(total_anime * 0.01))\n",
    "    frequent_genres = genre_counts[genre_counts >= min_count].index.tolist()\n",
    "    rare_genre_columns = [col for col in genre_columns if col not in frequent_genres]\n",
    "    \n",
    "    if rare_genre_columns:\n",
    "        df_train['Genre_Other'] = df_train[rare_genre_columns].max(axis=1)\n",
    "        df_train = df_train.drop(columns=rare_genre_columns)\n",
    "    \n",
    "    # === STUDIOS ===\n",
    "    studio_columns = [col for col in df_train.columns if col.startswith('Studios_')]\n",
    "    studio_counts = df_train[studio_columns].sum().sort_values(ascending=False)\n",
    "    \n",
    "    min_count = max(10, int(total_anime * 0.01))\n",
    "    frequent_studios = studio_counts[studio_counts >= min_count].index.tolist()\n",
    "    rare_studio_columns = [col for col in studio_columns if col not in frequent_studios]\n",
    "    \n",
    "    if rare_studio_columns:\n",
    "        df_train['Studio_Other'] = df_train[rare_studio_columns].max(axis=1)\n",
    "        df_train = df_train.drop(columns=rare_studio_columns)\n",
    "\n",
    "    # === ALIGN ALL COLUMNS ===\n",
    "    for col in df_train.columns:\n",
    "        if col not in df_test.columns:\n",
    "            df_test[col] = 0\n",
    "    \n",
    "    # Remove extra columns from test\n",
    "    for col in df_test.columns:\n",
    "        if col not in df_train.columns:\n",
    "            df_test = df_test.drop(columns=[col])\n",
    "    \n",
    "    # Ensure same order\n",
    "    df_test = df_test[df_train.columns]\n",
    "    \n",
    "    return df_train, df_test"
   ],
   "id": "c7f64fb926b9493a",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RULE-BASED CLASSIFICATION FUNCTIONS",
   "id": "8c0430ad8f76e6e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:08:21.495309Z",
     "start_time": "2025-10-05T12:08:21.463723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_user_preferences(df):\n",
    "    watched = df[df['score']>0].copy()\n",
    "        \n",
    "    preferences = {\n",
    "        'overall_mean': watched['score'].mean(),\n",
    "        'genre_scores': {},\n",
    "        'studios_scores': {},\n",
    "        'type_scores': {},\n",
    "        'rating_scores': {},\n",
    "        'year_scores': {}        \n",
    "    }\n",
    "    \n",
    "    genre_cols = [col for col in watched.columns if col.startswith('Genre_')]\n",
    "    for genre_col in genre_cols:\n",
    "        genre_name = genre_col.replace('Genre_', '').strip()\n",
    "        mask = (watched[genre_col] == 1)       \n",
    "        if mask.sum() >= 5 :\n",
    "            preferences['genre_scores'][genre_name] = watched[mask]['score'].mean()\n",
    "            \n",
    "    studio_cols = [col for col in watched.columns if col.startswith('Studios_')]\n",
    "    for studio_col in studio_cols:\n",
    "        studio_name = studio_col.replace('Studios_', '').strip()\n",
    "        mask = (watched[studio_col] == 1)\n",
    "        if mask.sum() >= 5 :\n",
    "            preferences['studios_scores'][studio_name] = watched[mask]['score'].mean()\n",
    "            \n",
    "    type_cols = [col for col in watched.columns if col.startswith('Type_')]\n",
    "    for type_col in type_cols:\n",
    "        type_name = type_col.replace('Type_', '')\n",
    "        mask = (watched[type_col] == 1)\n",
    "        if mask.sum() >= 3:\n",
    "            preferences['type_scores'][type_name] = watched[mask]['score'].mean()\n",
    "    \n",
    "    rating_cols = [col for col in watched.columns if col.startswith('Rating_')]\n",
    "    for rating_col in rating_cols:\n",
    "        rating_name = rating_col.replace('Rating_', '').strip()\n",
    "        mask = (watched[rating_col] == 1)\n",
    "        if mask.sum() >= 3:\n",
    "            preferences['rating_scores'][rating_name] = watched[mask]['score'].mean()\n",
    "    \n",
    "    watched['year'] = watched['year'].astype(int)\n",
    "    year_groups  = watched.groupby('year')['score'].apply(list)\n",
    "    for year, scores in year_groups.items():\n",
    "        if len(scores) >= 5:\n",
    "            preferences['year_scores'][year] = np.mean(scores)\n",
    "    \n",
    "    return preferences"
   ],
   "id": "d5a8b5ed6e8e935",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:08:21.764552Z",
     "start_time": "2025-10-05T12:08:21.748610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_personal_score(anime_row,user_prefs):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param anime_row:  row with anime characteristics\n",
    "    :param user_prefs: user preferences\n",
    "    :return: expected score for new anime\n",
    "    \"\"\"\n",
    "    score = user_prefs['overall_mean']\n",
    "    adjustments = []\n",
    "\n",
    "    \n",
    "    # RULE 1: Genres\n",
    "    genre_cols = [col for col in anime_row.index if col.startswith('Genre_')]\n",
    "    anime_genres = [col.replace('Genre_', '') for col in genre_cols if anime_row[col] == 1]\n",
    "    \n",
    "    for genre in anime_genres:\n",
    "        if genre in user_prefs['genre_scores']:\n",
    "            # Stronger adjustment: difference from mean, not absolute value\n",
    "            genre_diff = user_prefs['genre_scores'][genre] - score\n",
    "            adjustments.append(genre_diff * 0.5) \n",
    "        \n",
    "    # RULE 2: Studios\n",
    "    studios_cols = [col for col in anime_row.index if col.startswith('Studios_')]\n",
    "    anime_studios = [col.replace('Studios_', '') for col in studios_cols if anime_row[col] == 1]\n",
    "    for studio in anime_studios:\n",
    "        if studio in user_prefs['studios_scores']:\n",
    "            studio_diff = user_prefs['studios_scores'][studio] - score\n",
    "            adjustments.append(studio_diff * 0.3) \n",
    "\n",
    "        \n",
    "    # RULE 3: Type\n",
    "    type_cols = [col for col in anime_row.index if col.startswith('Type_')]\n",
    "    anime_type = [col.replace('Type_', '') for col in type_cols if anime_row[col] == 1]\n",
    "    \n",
    "    if anime_type and anime_type[0] in user_prefs['type_scores']:\n",
    "        type_diff = user_prefs['type_scores'][anime_type[0]] - score\n",
    "        adjustments.append(type_diff * 0.2)\n",
    "    \n",
    "    # RULE 4: Rating\n",
    "    rating_cols = [col for col in anime_row.index if col.startswith('Rating_')]\n",
    "    anime_rating = [col.replace('Rating_', '') for col in rating_cols if anime_row[col] == 1]\n",
    "    \n",
    "    if anime_rating and anime_rating[0] in user_prefs['rating_scores']:\n",
    "        rating_score = user_prefs['rating_scores'][anime_rating[0]]\n",
    "        \n",
    "    if adjustments:\n",
    "        final_score = score + sum(adjustments)\n",
    "    else:\n",
    "        final_score = score\n",
    "    \n",
    "    return np.clip(final_score, 0, 10)"
   ],
   "id": "138cf499a465e141",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PREPARING DATAFRAMES",
   "id": "b03201f375da7e10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:08:24.148366Z",
     "start_time": "2025-10-05T12:08:22.425208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df[df['score'] > 0].copy()\n",
    "df_ml = df.copy()\n",
    "df_rb = df.copy()\n",
    "\n",
    "# df_ml = prepare_for_ml(df_ml)   # This should create 'score_class'\n",
    "df_rb = prepare_for_rules(df_rb) # This keeps 'score' as continuous\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# For ML model (classification)\n",
    "df_train_ml = df_ml.loc[train_idx].copy()\n",
    "df_test_ml = df_ml.loc[test_idx].copy()\n",
    "\n",
    "q33 = df_train_ml['score'].quantile(0.33)\n",
    "q66 = df_train_ml['score'].quantile(0.66)\n",
    "\n",
    "df_train_ml = prepare_for_ml(df_train_ml, q33=q33, q66=q66)\n",
    "df_test_ml = prepare_for_ml(df_test_ml, q33=q33, q66=q66)\n",
    "\n",
    "df_train_ml, df_test_ml = group_rare_features(df_train_ml, df_test_ml)\n",
    "\n",
    "# For rule-based model (regression)\n",
    "df_train_rb = df_rb.loc[train_idx].copy()\n",
    "df_test_rb = df_rb.loc[test_idx].copy()\n",
    "\n",
    "# For ML model\n",
    "X_train_ml = df_train_ml.drop(columns=['score', 'title', 'id', 'score_class'])\n",
    "y_train_ml = df_train_ml['score_class']\n",
    "X_test_ml = df_test_ml.drop(columns=['score', 'title', 'id', 'score_class'])\n",
    "y_test_ml = df_test_ml['score_class']\n",
    "\n",
    "# For rule-based model\n",
    "X_train_rb = df_train_rb.drop(columns=['score', 'title', 'id'])\n",
    "y_train_rb = df_train_rb['score']\n",
    "X_test_rb = df_test_rb.drop(columns=['score', 'title', 'id'])\n",
    "y_test_rb = df_test_rb['score']\n",
    "\n",
    "X_train_ml, X_test_ml = use_affinity(X_train_ml, X_test_ml, y_train_rb) # rb contains 'score' while y_train_ml 'score_class'\n",
    "\n",
    "user_prefs = analyze_user_preferences(df_train_rb)"
   ],
   "id": "d2be8e3a2d88d16d",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:10:38.003809Z",
     "start_time": "2025-10-03T19:10:37.016094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_rules = []\n",
    "for idx in range(len(X_test_rb)):\n",
    "    anime = X_test_rb.iloc[idx]\n",
    "    pred = predict_personal_score(anime, user_prefs)\n",
    "    y_pred_rules.append(pred)\n",
    "\n",
    "y_pred_rules = np.array(y_pred_rules)"
   ],
   "id": "cdbb1d77504f3624",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TRAINING MODELS",
   "id": "60b0795826645d7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:10:39.501640Z",
     "start_time": "2025-10-03T19:10:39.484103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_ml),\n",
    "    y=y_train_ml\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ],
   "id": "a5f3c1d108dd6ff1",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:12:42.041443Z",
     "start_time": "2025-10-03T19:11:22.438916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [ 200, 300, 400],\n",
    "    'max_depth': [15, 20 ],\n",
    "    'min_samples_split': [ 10, 20],\n",
    "    'min_samples_leaf': [ 4, 8, 10],\n",
    "    'max_features': ['sqrt', 0.3],\n",
    "    'class_weight': ['balanced_subsample']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='balanced_accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "# Use best model\n",
    "ml_model = grid_search.best_estimator_"
   ],
   "id": "6c8f427431a5f0a7",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:14:04.348903Z",
     "start_time": "2025-10-03T19:14:04.336386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "most_common = mode(y_train_ml, keepdims=True).mode[0]\n",
    "baseline_acc = (y_test_ml == most_common).mean()\n",
    "\n",
    "print(f\"Baseline (always predict {most_common}): {baseline_acc:.3f}\")\n",
    "print(f\"Model: 0.622\")\n",
    "print(f\"Improvement over baseline: {0.622 - baseline_acc:.3f}\")"
   ],
   "id": "71c0a70321596dbb",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:14:44.191219Z",
     "start_time": "2025-10-03T19:14:36.774897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=300,min_samples_leaf=2,min_samples_split=10, class_weight='balanced', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=300, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=300, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    acc = accuracy_score(y_test_ml, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} Accuracy: {acc:.3f}\")\n",
    "\n",
    "# Show best\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"\\n🏆 Best: {best_model} ({results[best_model]:.3f})\")"
   ],
   "id": "7d42f6d05f6709eb",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:19:13.648338Z",
     "start_time": "2025-10-03T19:19:12.469344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_model = RandomForestClassifier(n_estimators=300,min_samples_leaf=2,min_samples_split=10, class_weight='balanced', random_state=42)\n",
    "ml_model.fit(X_train_ml, y_train_ml)"
   ],
   "id": "ef1f4e56f631422a",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### COMPARING 2 APROACHES  ",
   "id": "8751e4b47148ac9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:19:20.419468Z",
     "start_time": "2025-10-03T19:19:19.533470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predictions\n",
    "y_pred_ml = ml_model.predict(X_test_ml)  # ML model predictions\n",
    "y_pred_rules = []\n",
    "for idx in range(len(X_test_rb)):\n",
    "    anime = X_test_rb.iloc[idx]\n",
    "    pred = predict_personal_score(anime, user_prefs)\n",
    "    y_pred_rules.append(pred)\n",
    "\n",
    "# Convert rule-based continuous scores to classes\n",
    "y_pred_rules_class = [classify_3_classes(score, q33,q66) for score in y_pred_rules]\n",
    "\n",
    "# Compare accuracies\n",
    "ml_accuracy = accuracy_score(y_test_ml, y_pred_ml)\n",
    "rules_accuracy = accuracy_score(y_test_ml, y_pred_rules_class)\n",
    "\n",
    "print(f\"ML Model Accuracy: {ml_accuracy:.3f}\")\n",
    "print(f\"Rule-Based Accuracy: {rules_accuracy:.3f}\")"
   ],
   "id": "4160a0c36b86a030",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:19:22.834242Z",
     "start_time": "2025-10-03T19:19:22.817704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BASELINE MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from scipy.stats import mode\n",
    "most_common = mode(y_train_ml, keepdims=True).mode[0]\n",
    "y_pred_baseline = np.full(len(y_test_ml), most_common)\n",
    "baseline_acc = accuracy_score(y_test_ml, y_pred_baseline)\n",
    "\n",
    "print(f\"Always predict class {most_common}: {baseline_acc:.3f}\")\n",
    "\n",
    "# Baseline 2: Random predictions\n",
    "np.random.seed(42)\n",
    "y_pred_random = np.random.choice([0, 1, 2], size=len(y_test_ml))\n",
    "random_acc = accuracy_score(y_test_ml, y_pred_random)\n",
    "\n",
    "print(f\"Random predictions: {random_acc:.3f}\")\n",
    "\n",
    "print(f\"\\nYour ML model: {ml_accuracy}\")\n",
    "print(f\"Your Rule-based: {rules_accuracy}\")\n",
    "\n",
    "if ml_accuracy < baseline_acc:\n",
    "    print(\"\\nML model is WORSE than baseline!\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_distribution(y, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"  Class {cls}: {count:4d} ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "analyze_distribution(y_train_ml, \"Training set\")\n",
    "analyze_distribution(y_test_ml, \"Test set\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRIX ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_and_analyze_cm(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"Confusion Matrix (rows=true, cols=predicted):\")\n",
    "    print(\"        Bad  Avg  Good\")\n",
    "    for i, row in enumerate(cm):\n",
    "        class_names = ['Bad   ', 'Average', 'Good  ']\n",
    "        print(f\"{class_names[i]}: {row}\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        total = cm[i].sum()\n",
    "        correct = cm[i][i]\n",
    "        print(f\"\\nClass {i} ({['Bad', 'Average', 'Good'][i]}):\")\n",
    "        print(f\"  Correct: {correct}/{total} ({correct/total*100:.1f}%)\")\n",
    "        \n",
    "        for j in range(3):\n",
    "            if i != j and cm[i][j] > 0:\n",
    "                print(f\"  Misclassified as {['Bad', 'Average', 'Good'][j]}: {cm[i][j]} ({cm[i][j]/total*100:.1f}%)\")\n",
    "\n",
    "plot_and_analyze_cm(y_test_ml, y_pred_ml, \"ML Model\")\n",
    "plot_and_analyze_cm(y_test_ml, y_pred_rules_class, \"Rule-Based Model\")\n"
   ],
   "id": "cea4c506c36db8b7",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regressor model",
   "id": "d2264204d48899d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T12:09:52.135258Z",
     "start_time": "2025-10-05T12:09:47.296293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df_train_reg = df_train_ml.copy()\n",
    "X_train_reg = df_train_reg.drop(columns=['score', 'score_class', 'title', 'id'])\n",
    "y_train_reg = df_train_reg['score']\n",
    "\n",
    "# Train regressor\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=10,\n",
    "    random_state=42\n",
    ")\n",
    "rf_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "X_test_reg = df_test_ml.drop(columns=['score', 'score_class', 'title', 'id'])\n",
    "y_test_reg = df_test_ml['score']\n",
    "\n",
    "y_pred_reg = rf_reg.predict(X_test_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "\n",
    "# Compare to baseline\n",
    "baseline_mae = mean_absolute_error(y_test_reg, np.full(len(y_test_reg), y_train_reg.mean()))\n",
    "\n",
    "print(f\"Baseline MAE: {baseline_mae:.3f}\")\n",
    "print(f\"Model MAE: {mae:.3f}\")\n",
    "print(f\"Improvement: {(baseline_mae - mae)/baseline_mae * 100:.1f}%\")"
   ],
   "id": "920e037ac50e3aec",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "8cfa7596289672b6",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
